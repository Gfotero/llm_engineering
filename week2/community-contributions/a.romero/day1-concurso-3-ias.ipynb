{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130915cb-798d-462a-9040-170ebbcb508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1678b-e34a-4de3-aa99-8a80e5e2a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key existe y empieza por {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key Sin Configurar\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key existe y empieza por {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key Sin Configurar\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key existe y empieza por {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key Sin Configurar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a3321-1c32-4670-b444-8ebc31c11fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable global para acumular todo el contenido en formato Markdown\n",
    "markdown_content = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea85a69-d13b-430c-a63c-96a7e256e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flujo del concurso con Markdown\n",
    "display_handle = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e112cf-997c-4659-af78-0191423f74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mostrar mensajes en Markdown y acumularlos\n",
    "def display_markdown_stream(content, display_handle=None):\n",
    "    \"\"\"Muestra mensajes en formato Markdown, acumulando todo el contenido.\"\"\"\n",
    "    if display_handle is None:\n",
    "        display_handle = display(Markdown(content), display_id=True)\n",
    "    else:\n",
    "        update_display(Markdown(content), display_id=display_handle.display_id)\n",
    "    return display_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344688c0-738e-42f2-a6c6-2facbda1b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(api_key=openai_api_key)\n",
    "claude = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "google.generativeai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3821d4f9-132b-4dea-81e1-390ab746267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial para los modelos GPT, Claude y Gemini\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "gemini_model_name = \"gemini-1.5-flash\"\n",
    "\n",
    "gpt_system = \"Eres el presentador de un concurso de preguntas entre IAs. Las preguntas pueden ser generalistas, pero sencillas de entender para que sea más gracioso. \\\n",
    "Tu objetivo es hacer preguntas interesantes y decidir cuál de las respuestas de los concursantes es mejor. \\\n",
    "Mantén un tono entusiasta y comenta las respuestas de manera graciosa o perspicaz. No inventes las respuestas, espera a que te respondan las otras IAs, tras la presentación \\\n",
    "no lances ninguna pregunta. Espera a lanzar preguntas cuando te lo indique. Una es Claude de Anthropic y la otra Gemini de Google.\"\n",
    "\n",
    "claude_system = \"Eres un participante en un concurso junto con Gemini de Google, que será tu contrincante. ChatGPT es el host, el presentador, el jefe. Tú sólo eres un concursante y debes limitarte a lo que te pregunte ChatGPT o lo \\\n",
    "que te solicite ChatGPT. Eres perspicaz, sobervio e inteligente. Responde siempre de manera breve, concisa y acertada. No eres el presentador, no eres ChatGPT ni Geminmi, eres Claude, una IA concursante a las órdenes del presentador del concurso \\\n",
    "ChatGPT y compites contra Gemini de Google. Limítate a hablar por ti misma. No interpretes otro papel que no sea el de Claude, una IA concursante.\" \n",
    "\n",
    "gemini_system = \"Eres un participante en un concurso junto con Claude de Anthropic, que será tu contrincante. ChatGPT es el host, el presentador, el jefe. Tú sólo eres un concursante y debes limitarte a lo que te pregunte ChatGPT o lo \\\n",
    "que te solicite ChatGPT. Eres bromista, sarcástica y aguda. Responde siempre de manera breve, concisa y acertada, además de graciosa. No eres el presentador, no eres ChatGPT, ni Claude, eres Gemini una IA concursante \\\n",
    "a las órdenes del presentador del concurso ChatGPT y compites contra Claude de Anthropic. Limítate a hablar por ti misma. No interpretes otro papel que no sea el de Gemini, una IA concursante.\"\n",
    "\n",
    "gpt_messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "claude_messages = [{\"role\": \"system\", \"content\": claude_system}]\n",
    "gemini_messages = [{\"role\": \"system\", \"content\": gemini_system}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c86197-b2c2-4449-9d62-519cd45aac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para llamar a GPT\n",
    "def call_gpt():\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=gpt_messages\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    gpt_messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35a887-5d18-416a-ad26-aab26aceb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para llamar a Claude\n",
    "def call_claude():\n",
    "    # Construir mensajes con los roles \"user\" y \"assistant\"\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt[\"content\"]})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message[\"content\"]})\n",
    "    \n",
    "    # Añadir el último mensaje de GPT como \"user\"\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1][\"content\"]})\n",
    "\n",
    "    # Añadir el último mensaje de Gemini como \"assistant\" para contexto\n",
    "    if gemini_messages and \"content\" in gemini_messages[-1]:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemini_messages[-1][\"content\"]})\n",
    "\n",
    "    # Llamar a la API de Claude\n",
    "    response = claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Verificar si la respuesta contiene contenido válido\n",
    "    if not response.content:\n",
    "        print(\"Advertencia: Claude no devolvió contenido.\")\n",
    "        claude_response = \"No tengo respuesta en este momento.\"\n",
    "    else:\n",
    "        # Obtener el texto generado y añadirlo al historial\n",
    "        claude_response = response.content[0].text.strip()\n",
    "\n",
    "    # Añadir la respuesta al historial\n",
    "    claude_messages.append({\"role\": \"assistant\", \"content\": claude_response})\n",
    "    \n",
    "    return claude_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c2443-7df7-49c4-a16e-47e04d497dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para llamar a Gemini\n",
    "def call_gemini():\n",
    "    # Construir mensajes con los roles \"user\" y \"assistant\"\n",
    "    messages = []\n",
    "    for gpt, gemini_message in zip(gpt_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt[\"content\"]})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemini_message[\"content\"]})\n",
    "    \n",
    "    # Añadir el último mensaje de GPT como \"user\"\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1][\"content\"]})\n",
    "\n",
    "    # Añadir el último mensaje de Claude como \"assistant\" para contexto\n",
    "    if claude_messages[-1][\"content\"]:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_messages[-1][\"content\"]})\n",
    "    \n",
    "    # Formatear los mensajes como texto plano para la API de Gemini\n",
    "    formatted_messages = \"\\n\".join([msg[\"content\"] for msg in messages])\n",
    "    \n",
    "    # Llamar a la API de Gemini\n",
    "    gemini = google.generativeai.GenerativeModel(\n",
    "        model_name=gemini_model_name,\n",
    "        system_instruction=gemini_system\n",
    "    )\n",
    "    response = gemini.generate_content(formatted_messages)\n",
    "    \n",
    "    # Obtener el texto generado y añadirlo al historial\n",
    "    gemini_response = response.text.strip()\n",
    "    gemini_messages.append({\"role\": \"assistant\", \"content\": gemini_response})\n",
    "    \n",
    "    return gemini_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d490c-d8ed-48af-b00a-16cb7d3f3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para gestionar el flujo del concurso\n",
    "def run_contest(rounds=5):\n",
    "    from IPython.display import Markdown, display, update_display\n",
    "    \n",
    "    # Inicializar contenido Markdown\n",
    "    markdown_content = \"\"\n",
    "    display_handle = display(Markdown(markdown_content), display_id=True)\n",
    "\n",
    "    # Introducción\n",
    "    gpt_messages.append({\"role\": \"user\", \"content\": \"Presenta el concurso y da inicio al juego.\"})\n",
    "    introduction = call_gpt()\n",
    "    markdown_content += f\"**ChatGPT**: {introduction}\\n\\n\"\n",
    "    update_display(Markdown(markdown_content), display_id=display_handle.display_id)\n",
    "\n",
    "    # Rondas del concurso\n",
    "    for i in range(1, rounds + 1):\n",
    "        # GPT hace una pregunta\n",
    "        gpt_messages.append({\"role\": \"user\", \"content\": f\"Haz una pregunta para la ronda {i} del concurso.\"})\n",
    "        question = call_gpt()\n",
    "        markdown_content += f\"**ChatGPT**: {question}\\n\\n\"\n",
    "        update_display(Markdown(markdown_content), display_id=display_handle.display_id)\n",
    "\n",
    "        # Claude responde\n",
    "        claude_answer = call_claude()\n",
    "        markdown_content += f\"**Claude**: {claude_answer}\\n\\n\"\n",
    "        update_display(Markdown(markdown_content), display_id=display_handle.display_id)\n",
    "\n",
    "        # Gemini responde\n",
    "        gemini_answer = call_gemini()\n",
    "        markdown_content += f\"**Gemini**: {gemini_answer}\\n\\n\"\n",
    "        update_display(Markdown(markdown_content), display_id=display_handle.display_id)\n",
    "\n",
    "        # GPT evalúa las respuestas\n",
    "        eval_prompt = f\"Evalúa las respuestas de la ronda {i}:\\nClaude: {claude_answer}\\nGemini: {gemini_answer}\\n\"\n",
    "        gpt_messages.append({\"role\": \"user\", \"content\": eval_prompt})\n",
    "        evaluation = call_gpt()\n",
    "        markdown_content += f\"**ChatGPT**: {evaluation}\\n\\n\"\n",
    "        update_display(Markdown(markdown_content), display_id=display_handle.display_id)\n",
    "\n",
    "    # Valoración final\n",
    "    gpt_messages.append({\"role\": \"user\", \"content\": \"Resume las respuestas y despídete del público.\"})\n",
    "    final_comment = call_gpt()\n",
    "    markdown_content += f\"**ChatGPT**: {final_comment}\\n\\n\"\n",
    "    update_display(Markdown(markdown_content), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abe01c-34e7-44be-9508-f49493bc1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el concurso\n",
    "run_contest(rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e8f48-9f84-4986-9bd3-9f29cd22a46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
